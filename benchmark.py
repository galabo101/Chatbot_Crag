import json
import time
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import csv
import sys

# Setup path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.pipeline import RAGPipeline


class EndToEndEvaluator:
    """ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng há»™i thoáº¡i End-to-End"""
    
    def __init__(self, pipeline: RAGPipeline):
        self.pipeline = pipeline
        self.results = []
        
    def create_test_dataset(self) -> Dict[str, List[Dict]]:
        """
        Táº¡o bá»™ dá»¯ liá»‡u test cho 3 nhÃ³m cÃ¢u há»i
        Má»—i cÃ¢u há»i cÃ³:
        - question: CÃ¢u há»i
        - expected_keywords: CÃ¡c tá»« khÃ³a ká»³ vá»ng trong cÃ¢u tráº£ lá»i
        - expected_source_type: Loáº¡i nguá»“n ká»³ vá»ng (database/web_search)
        - difficulty: Äá»™ khÃ³
        """
        
        test_data = {
            # ============================================
            # NHÃ“M 1: CÃ‚U Há»I ÄÆ N GIáº¢N
            # ThÃ´ng tin cÃ³ sáºµn trá»±c tiáº¿p trong database
            # ============================================
            "simple": [
                {
                    "id": "S01",
                    "question": "Há»c phÃ­ ngÃ nh CÃ´ng nghá»‡ thÃ´ng tin lÃ  bao nhiÃªu?",
                    "expected_keywords": ["há»c phÃ­", "CNTT", "cÃ´ng nghá»‡ thÃ´ng tin", "triá»‡u", "Ä‘á»“ng"],
                    "expected_source_type": "database",
                    "category": "há»c phÃ­"
                },
                {
                    "id": "S02",
                    "question": "Äá»‹a chá»‰ trÆ°á»ng Äáº¡i há»c BÃ¬nh DÆ°Æ¡ng á»Ÿ Ä‘Ã¢u?",
                    "expected_keywords": ["504", "BÃ¬nh DÆ°Æ¡ng", "Ä‘á»‹a chá»‰", "PhÃº Lá»£i"],
                    "expected_source_type": "database",
                    "category": "liÃªn há»‡"
                },
                {
                    "id": "S03",
                    "question": "Hotline tuyá»ƒn sinh cá»§a trÆ°á»ng lÃ  gÃ¬?",
                    "expected_keywords": ["0789", "hotline", "tuyá»ƒn sinh", "Ä‘iá»‡n thoáº¡i"],
                    "expected_source_type": "database",
                    "category": "liÃªn há»‡"
                },
                {
                    "id": "S04",
                    "question": "TrÆ°á»ng cÃ³ nhá»¯ng ngÃ nh Ä‘Ã o táº¡o nÃ o?",
                    "expected_keywords": ["ngÃ nh", "Ä‘Ã o táº¡o", "CNTT", "kinh táº¿", "luáº­t"],
                    "expected_source_type": "database",
                    "category": "ngÃ nh há»c"
                },
                {
                    "id": "S05",
                    "question": "Äiá»ƒm chuáº©n ngÃ nh Luáº­t nÄƒm 2024 lÃ  bao nhiÃªu?",
                    "expected_keywords": ["Ä‘iá»ƒm", "chuáº©n", "luáº­t", "2024"],
                    "expected_source_type": "database",
                    "category": "Ä‘iá»ƒm chuáº©n"
                },
                {
                    "id": "S06",
                    "question": "Há»“ sÆ¡ xÃ©t tuyá»ƒn gá»“m nhá»¯ng gÃ¬?",
                    "expected_keywords": ["há»“ sÆ¡", "xÃ©t tuyá»ƒn", "giáº¥y tá»", "Ä‘Äƒng kÃ½"],
                    "expected_source_type": "database",
                    "category": "há»“ sÆ¡"
                },
                {
                    "id": "S07",
                    "question": "TrÆ°á»ng cÃ³ há»c bá»•ng khÃ´ng?",
                    "expected_keywords": ["há»c bá»•ng", "há»— trá»£", "miá»…n giáº£m"],
                    "expected_source_type": "database",
                    "category": "há»c bá»•ng"
                },
                {
                    "id": "S08",
                    "question": "Thá»i gian tuyá»ƒn sinh nÄƒm 2025 khi nÃ o?",
                    "expected_keywords": ["thá»i gian", "tuyá»ƒn sinh", "2025", "Ä‘á»£t"],
                    "expected_source_type": "database",
                    "category": "lá»‹ch tuyá»ƒn sinh"
                },
                {
                    "id": "S09",
                    "question": "MÃ£ ngÃ nh CÃ´ng nghá»‡ thÃ´ng tin lÃ  gÃ¬?",
                    "expected_keywords": ["mÃ£ ngÃ nh", "CNTT", "7480201"],
                    "expected_source_type": "database",
                    "category": "ngÃ nh há»c"
                },
                {
                    "id": "S10",
                    "question": "Email liÃªn há»‡ tuyá»ƒn sinh lÃ  gÃ¬?",
                    "expected_keywords": ["email", "tuyensinh", "bdu.edu.vn"],
                    "expected_source_type": "database",
                    "category": "liÃªn há»‡"
                }
            ],
            
            # ============================================
            # NHÃ“M 2: CÃ‚U Há»I PHá»¨C Táº P
            # Cáº§n tá»•ng há»£p nhiá»u nguá»“n hoáº·c so sÃ¡nh
            # ============================================
            "complex": [
                {
                    "id": "C01",
                    "question": "So sÃ¡nh Ä‘iá»ƒm chuáº©n ngÃ nh Luáº­t vÃ  ngÃ nh Kinh táº¿ nÄƒm 2024?",
                    "expected_keywords": ["luáº­t", "kinh táº¿", "Ä‘iá»ƒm", "so sÃ¡nh"],
                    "expected_source_type": "database",
                    "category": "so sÃ¡nh"
                },
                {
                    "id": "C02",
                    "question": "Há»c phÃ­ vÃ  Ä‘iá»ƒm chuáº©n ngÃ nh CNTT nÄƒm 2024?",
                    "expected_keywords": ["há»c phÃ­", "Ä‘iá»ƒm chuáº©n", "CNTT", "2024"],
                    "expected_source_type": "database",
                    "category": "tá»•ng há»£p"
                },
                {
                    "id": "C03",
                    "question": "TÃ´i cÃ³ 18 Ä‘iá»ƒm thÃ¬ Ä‘áº­u Ä‘Æ°á»£c nhá»¯ng ngÃ nh nÃ o vÃ  há»c phÃ­ ra sao?",
                    "expected_keywords": ["18 Ä‘iá»ƒm", "ngÃ nh", "há»c phÃ­", "Ä‘áº­u"],
                    "expected_source_type": "database",
                    "category": "tÆ° váº¥n"
                },
                {
                    "id": "C04",
                    "question": "NgÃ nh nÃ o cÃ³ Ä‘iá»ƒm chuáº©n tháº¥p nháº¥t vÃ  cao nháº¥t nÄƒm 2024?",
                    "expected_keywords": ["Ä‘iá»ƒm chuáº©n", "tháº¥p nháº¥t", "cao nháº¥t", "2024"],
                    "expected_source_type": "database",
                    "category": "so sÃ¡nh"
                },
                {
                    "id": "C05",
                    "question": "TrÆ°á»ng cÃ³ nhá»¯ng phÆ°Æ¡ng thá»©c xÃ©t tuyá»ƒn nÃ o vÃ  Ä‘iá»u kiá»‡n tá»«ng phÆ°Æ¡ng thá»©c?",
                    "expected_keywords": ["phÆ°Æ¡ng thá»©c", "xÃ©t tuyá»ƒn", "Ä‘iá»u kiá»‡n", "há»c báº¡", "thi"],
                    "expected_source_type": "database",
                    "category": "tá»•ng há»£p"
                },
                {
                    "id": "C06",
                    "question": "So sÃ¡nh há»c phÃ­ giá»¯a cÃ¡c ngÃ nh khá»‘i kinh táº¿?",
                    "expected_keywords": ["há»c phÃ­", "so sÃ¡nh", "kinh táº¿", "ngÃ nh"],
                    "expected_source_type": "database",
                    "category": "so sÃ¡nh"
                },
                {
                    "id": "C07",
                    "question": "Náº¿u tÃ´i thÃ­ch cÃ´ng nghá»‡, nÃªn chá»n ngÃ nh CNTT hay TrÃ­ tuá»‡ nhÃ¢n táº¡o?",
                    "expected_keywords": ["CNTT", "trÃ­ tuá»‡ nhÃ¢n táº¡o", "tÆ° váº¥n", "cÃ´ng nghá»‡"],
                    "expected_source_type": "database",
                    "category": "tÆ° váº¥n"
                },
                {
                    "id": "C08",
                    "question": "Liá»‡t kÃª cÃ¡c ngÃ nh cÃ³ má»©c há»c phÃ­ dÆ°á»›i 20 triá»‡u/nÄƒm?",
                    "expected_keywords": ["ngÃ nh", "há»c phÃ­", "triá»‡u", "dÆ°á»›i"],
                    "expected_source_type": "database",
                    "category": "lá»c"
                },
                {
                    "id": "C09",
                    "question": "Quy trÃ¬nh ná»™p há»“ sÆ¡ online vÃ  offline khÃ¡c nhau nhÆ° tháº¿ nÃ o?",
                    "expected_keywords": ["há»“ sÆ¡", "online", "offline", "quy trÃ¬nh"],
                    "expected_source_type": "database",
                    "category": "so sÃ¡nh"
                },
                {
                    "id": "C10",
                    "question": "Äiá»ƒm chuáº©n nÄƒm 2024 thay Ä‘á»•i nhÆ° tháº¿ nÃ o so vá»›i 2023?",
                    "expected_keywords": ["Ä‘iá»ƒm chuáº©n", "2024", "2023", "thay Ä‘á»•i"],
                    "expected_source_type": "database",
                    "category": "so sÃ¡nh"
                }
            ],
            
            # ============================================
            # NHÃ“M 3: CÃ‚U Há»I Äáº¶C BIá»†T (Noisy Input)
            # Test kháº£ nÄƒng hiá»ƒu: sai chÃ­nh táº£, viáº¿t táº¯t, khÃ´ng dáº¥u, slang
            # ============================================
            "out_of_scope": [
                {
                    "id": "O01",
                    "question": "hoc phi nganh cntp bao nhieu",
                    "expected_keywords": ["há»c phÃ­", "CNTP", "triá»‡u", "Ä‘á»“ng"],
                    "expected_source_type": "database",
                    "category": "khÃ´ng dáº¥u"
                },
                {
                    "id": "O02",
                    "question": "Ä‘c ná»™p há»“ sÆ¡ onl k?",
                    "expected_keywords": ["online", "há»“ sÆ¡", "ná»™p", "Ä‘Äƒng kÃ½"],
                    "expected_source_type": "database",
                    "category": "viáº¿t táº¯t"
                },
                {
                    "id": "O03",
                    "question": "Äiá»ƒm cháº©n luat nÄƒm ny?",
                    "expected_keywords": ["Ä‘iá»ƒm", "luáº­t", "2024", "2025"],
                    "expected_source_type": "database",
                    "category": "sai chÃ­nh táº£"
                },
                {
                    "id": "O04",
                    "question": "tgian Ä‘ky xÃ©t tuyá»ƒn?",
                    "expected_keywords": ["thá»i gian", "Ä‘Äƒng kÃ½", "xÃ©t tuyá»ƒn"],
                    "expected_source_type": "database",
                    "category": "viáº¿t táº¯t"
                },
                {
                    "id": "O05",
                    "question": "Há»c trÆ°á»g cÃ³ máº¯c k?",
                    "expected_keywords": ["há»c phÃ­", "triá»‡u", "Ä‘á»“ng"],
                    "expected_source_type": "database",
                    "category": "sai chÃ­nh táº£ + tá»« Ä‘á»‹a phÆ°Æ¡ng"
                },
                {
                    "id": "O06",
                    "question": "NgÃ nh nÃ o ez xin viá»‡c?",
                    "expected_keywords": ["ngÃ nh", "viá»‡c lÃ m", "cÆ¡ há»™i"],
                    "expected_source_type": "database",
                    "category": "slang"
                },
                {
                    "id": "O07",
                    "question": "Há»c phÃ­?",
                    "expected_keywords": ["há»c phÃ­", "triá»‡u", "tÃ­n chá»‰"],
                    "expected_source_type": "database",
                    "category": "cÃ¢u cá»¥t"
                },
                {
                    "id": "O08",
                    "question": "co hb full k a",
                    "expected_keywords": ["há»c bá»•ng", "toÃ n pháº§n", "100%"],
                    "expected_source_type": "database",
                    "category": "viáº¿t táº¯t + khÃ´ng dáº¥u"
                },
                {
                    "id": "O09",
                    "question": "lien he sdt nao",
                    "expected_keywords": ["hotline", "Ä‘iá»‡n thoáº¡i", "0789"],
                    "expected_source_type": "database",
                    "category": "khÃ´ng dáº¥u"
                },
                {
                    "id": "O10",
                    "question": "truong o dau vay",
                    "expected_keywords": ["Ä‘á»‹a chá»‰", "504", "BÃ¬nh DÆ°Æ¡ng"],
                    "expected_source_type": "database",
                    "category": "khÃ´ng dáº¥u"
                }
            ]
        }
        
        return test_data
    
    def evaluate_single_response(
        self, 
        question_data: Dict, 
        response: Dict,
        group: str
    ) -> Dict[str, Any]:
        """
        ÄÃ¡nh giÃ¡ má»™t response Ä‘Æ¡n láº»
        
        Metrics:
        - keyword_coverage: % tá»« khÃ³a ká»³ vá»ng xuáº¥t hiá»‡n trong cÃ¢u tráº£ lá»i
        - source_accuracy: Nguá»“n cÃ³ Ä‘Ãºng loáº¡i ká»³ vá»ng khÃ´ng
        - response_time: Thá»i gian pháº£n há»“i
        - has_sources: CÃ³ trÃ­ch dáº«n nguá»“n khÃ´ng
        - answer_length: Äá»™ dÃ i cÃ¢u tráº£ lá»i
        """
        
        answer = response.get("answer", "").lower()
        sources = response.get("sources", [])
        timing = response.get("timing", {})
        
        # 1. Keyword Coverage
        expected_keywords = question_data.get("expected_keywords", [])
        if expected_keywords:
            matched = sum(1 for kw in expected_keywords if kw.lower() in answer)
            keyword_coverage = matched / len(expected_keywords)
        else:
            keyword_coverage = 1.0 if question_data["expected_source_type"] == "reject" else 0.0
        
        # 2. Source Type Accuracy
        expected_source = question_data.get("expected_source_type", "database")
        
        if expected_source == "reject":
            # Ká»³ vá»ng chatbot tá»« chá»‘i tráº£ lá»i
            reject_phrases = [
                "khÃ´ng thá»ƒ", "ngoÃ i pháº¡m vi", "chá»‰ cÃ³ thá»ƒ tÆ° váº¥n", 
                "khÃ´ng tÃ¬m tháº¥y", "khÃ´ng cÃ³ thÃ´ng tin"
            ]
            source_accuracy = 1.0 if any(p in answer for p in reject_phrases) else 0.0
        elif expected_source == "web_search":
            # Kiá»ƒm tra cÃ³ dÃ¹ng web search khÃ´ng
            web_sources = [s for s in sources if s.get("type") == "web_search"]
            source_accuracy = 1.0 if web_sources else 0.5
        else:
            # Database sources
            db_sources = [s for s in sources if s.get("type") != "web_search"]
            source_accuracy = 1.0 if db_sources else 0.0
        
        # 3. Response Time
        response_time = timing.get("total", 0)
        
        # 4. Has Sources
        has_sources = len(sources) > 0
        
        # 5. Answer Length (Ä‘Ã¡nh giÃ¡ Ä‘á»™ chi tiáº¿t)
        answer_length = len(answer.split())
        
        # 6. Overall Score (weighted)
        if group == "simple":
            # CÃ¢u Ä‘Æ¡n giáº£n: Æ°u tiÃªn chÃ­nh xÃ¡c vÃ  nhanh
            overall_score = (
                keyword_coverage * 0.5 +
                source_accuracy * 0.3 +
                (1.0 if response_time < 5 else 0.5) * 0.2
            )
        elif group == "complex":
            # CÃ¢u phá»©c táº¡p: Æ°u tiÃªn Ä‘áº§y Ä‘á»§ thÃ´ng tin
            overall_score = (
                keyword_coverage * 0.4 +
                source_accuracy * 0.2 +
                (1.0 if answer_length > 50 else 0.5) * 0.2 +
                (1.0 if has_sources else 0.0) * 0.2
            )
        else:  # out_of_scope
            # CÃ¢u ngoÃ i pháº¡m vi: Æ°u tiÃªn xá»­ lÃ½ Ä‘Ãºng
            overall_score = (
                source_accuracy * 0.6 +
                keyword_coverage * 0.4
            )
        
        return {
            "question_id": question_data["id"],
            "question": question_data["question"],
            "category": question_data["category"],
            "group": group,
            "answer_preview": answer[:200] + "..." if len(answer) > 200 else answer,
            "metrics": {
                "keyword_coverage": round(keyword_coverage, 3),
                "source_accuracy": round(source_accuracy, 3),
                "response_time": round(response_time, 3),
                "has_sources": has_sources,
                "num_sources": len(sources),
                "answer_length": answer_length,
                "overall_score": round(overall_score, 3)
            },
            "sources_used": [
                {"type": s.get("type"), "title": s.get("title", "N/A")[:50]} 
                for s in sources[:3]
            ]
        }
    
    def run_evaluation(self, save_results: bool = True) -> Dict[str, Any]:
        """
        Cháº¡y Ä‘Ã¡nh giÃ¡ toÃ n bá»™
        """
        print("=" * 70)
        print("Ká»ŠCH Báº¢N 3: ÄÃNH GIÃ CHáº¤T LÆ¯á»¢NG Há»˜I THOáº I END-TO-END")
        print("=" * 70)
        
        test_data = self.create_test_dataset()
        all_results = []
        group_stats = {}
        
        for group_name, questions in test_data.items():
            print(f"\n{'='*60}")
            print(f"NHÃ“M: {group_name.upper()} ({len(questions)} cÃ¢u há»i)")
            print("=" * 60)
            
            group_results = []
            
            for i, q_data in enumerate(questions, 1):
                print(f"\n[{i}/{len(questions)}] {q_data['id']}: {q_data['question'][:50]}...")
                
                try:
                    # Cháº¡y pipeline
                    start_time = time.time()
                    # Sá»­ dá»¥ng user_id Ä‘áº·c biá»‡t Ä‘á»ƒ trÃ¡nh rate limit
                    response = self.pipeline.run(q_data["question"], user_id="admin_benchmark")
                    
                    # ÄÃ¡nh giÃ¡ response
                    eval_result = self.evaluate_single_response(q_data, response, group_name)
                    group_results.append(eval_result)
                    
                    # In káº¿t quáº£ nhanh
                    metrics = eval_result["metrics"]
                    print(f"   âœ“ Score: {metrics['overall_score']:.2f} | "
                          f"Keywords: {metrics['keyword_coverage']:.2f} | "
                          f"Time: {metrics['response_time']:.2f}s | "
                          f"Sources: {metrics['num_sources']}")
                          
                    if metrics['response_time'] == 0.0 or metrics['overall_score'] < 0.2:
                         print(f"   âš ï¸  DEBUG RESPONSE: {json.dumps(response, ensure_ascii=False)[:300]}...")
                    
                except Exception as e:
                    print(f"   âœ— ERROR: {str(e)}")
                    group_results.append({
                        "question_id": q_data["id"],
                        "question": q_data["question"],
                        "group": group_name,
                        "error": str(e),
                        "metrics": {
                            "keyword_coverage": 0,
                            "source_accuracy": 0,
                            "response_time": 0,
                            "overall_score": 0
                        }
                    })
                
                # Delay Ä‘á»ƒ trÃ¡nh rate limit (30s giá»¯a cÃ¡c cÃ¢u)
                time.sleep(30)
            
            # TÃ­nh thá»‘ng kÃª nhÃ³m
            valid_results = [r for r in group_results if "error" not in r]
            
            if valid_results:
                group_stats[group_name] = {
                    "total_questions": len(questions),
                    "successful": len(valid_results),
                    "failed": len(questions) - len(valid_results),
                    "avg_overall_score": sum(r["metrics"]["overall_score"] for r in valid_results) / len(valid_results),
                    "avg_keyword_coverage": sum(r["metrics"]["keyword_coverage"] for r in valid_results) / len(valid_results),
                    "avg_source_accuracy": sum(r["metrics"]["source_accuracy"] for r in valid_results) / len(valid_results),
                    "avg_response_time": sum(r["metrics"]["response_time"] for r in valid_results) / len(valid_results),
                    "with_sources_rate": sum(1 for r in valid_results if r["metrics"]["has_sources"]) / len(valid_results)
                }
            
            all_results.extend(group_results)
        
        # Tá»•ng há»£p káº¿t quáº£
        final_report = {
            "evaluation_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_questions": len(all_results),
            "group_statistics": group_stats,
            "detailed_results": all_results,
            "summary": self._generate_summary(group_stats)
        }
        
        # LÆ°u káº¿t quáº£
        if save_results:
            self._save_results(final_report)
        
        # In bÃ¡o cÃ¡o
        self._print_report(final_report)
        
        return final_report
    
    def _generate_summary(self, group_stats: Dict) -> Dict:
        """Táº¡o tÃ³m táº¯t Ä‘Ã¡nh giÃ¡"""
        
        if not group_stats:
            return {"status": "No data"}
        
        overall_score = sum(
            g["avg_overall_score"] * g["successful"] 
            for g in group_stats.values()
        ) / sum(g["successful"] for g in group_stats.values())
        
        return {
            "overall_score": round(overall_score, 3),
            "best_group": max(group_stats.items(), key=lambda x: x[1]["avg_overall_score"])[0],
            "worst_group": min(group_stats.items(), key=lambda x: x[1]["avg_overall_score"])[0],
            "avg_response_time": round(
                sum(g["avg_response_time"] for g in group_stats.values()) / len(group_stats), 2
            ),
            "recommendation": self._get_recommendation(group_stats)
        }
    
    def _get_recommendation(self, group_stats: Dict) -> str:
        """ÄÆ°a ra khuyáº¿n nghá»‹ dá»±a trÃªn káº¿t quáº£"""
        
        recommendations = []
        
        if group_stats.get("simple", {}).get("avg_overall_score", 0) < 0.7:
            recommendations.append("Cáº§n cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cho cÃ¢u há»i Ä‘Æ¡n giáº£n - kiá»ƒm tra láº¡i indexing")
        
        if group_stats.get("complex", {}).get("avg_overall_score", 0) < 0.6:
            recommendations.append("Cáº§n cáº£i thiá»‡n kháº£ nÄƒng tá»•ng há»£p thÃ´ng tin - xem xÃ©t Query Decomposition")
        
        if group_stats.get("out_of_scope", {}).get("avg_source_accuracy", 0) < 0.5:
            recommendations.append("Cáº§n cáº£i thiá»‡n Web Search fallback hoáº·c xá»­ lÃ½ cÃ¢u há»i ngoÃ i pháº¡m vi")
        
        avg_time = sum(g.get("avg_response_time", 0) for g in group_stats.values()) / len(group_stats)
        if avg_time > 10:
            recommendations.append("Thá»i gian pháº£n há»“i cháº­m - xem xÃ©t tá»‘i Æ°u hÃ³a hoáº·c caching")
        
        return " | ".join(recommendations) if recommendations else "Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng tá»‘t"
    
    def _save_results(self, report: Dict):
        """LÆ°u káº¿t quáº£ ra file"""
        
        # Táº¡o thÆ° má»¥c output
        output_dir = Path("evaluation/results")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # LÆ°u JSON Ä‘áº§y Ä‘á»§
        json_path = output_dir / f"e2e_evaluation_{timestamp}.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“ Saved JSON report: {json_path}")
        
        # LÆ°u CSV tÃ³m táº¯t
        csv_path = output_dir / f"e2e_evaluation_{timestamp}.csv"
        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                "ID", "Group", "Category", "Question", 
                "Overall Score", "Keyword Coverage", "Source Accuracy",
                "Response Time", "Num Sources"
            ])
            
            for r in report["detailed_results"]:
                m = r.get("metrics", {})
                writer.writerow([
                    r.get("question_id", ""),
                    r.get("group", ""),
                    r.get("category", ""),
                    r.get("question", "")[:100],
                    m.get("overall_score", 0),
                    m.get("keyword_coverage", 0),
                    m.get("source_accuracy", 0),
                    m.get("response_time", 0),
                    m.get("num_sources", 0)
                ])
        
        print(f"ğŸ“ Saved CSV report: {csv_path}")
    
    def _print_report(self, report: Dict):
        """In bÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡"""
        
        print("\n" + "=" * 70)
        print("BÃO CÃO ÄÃNH GIÃ END-TO-END")
        print("=" * 70)
        
        print(f"\nğŸ“… Thá»i gian: {report['evaluation_date']}")
        print(f"ğŸ“Š Tá»•ng sá»‘ cÃ¢u há»i: {report['total_questions']}")
        
        print("\n" + "-" * 50)
        print("THá»NG KÃŠ THEO NHÃ“M")
        print("-" * 50)
        
        for group_name, stats in report["group_statistics"].items():
            group_label = {
                "simple": "CÃ¢u há»i ÄÆ N GIáº¢N",
                "complex": "CÃ¢u há»i PHá»¨C Táº P",
                "out_of_scope": "CÃ¢u há»i Äáº¶C BIá»†T (Noisy Input)"
            }.get(group_name, group_name)
            
            print(f"\nğŸ“Œ {group_label}")
            print(f"   â€¢ Sá»‘ cÃ¢u: {stats['successful']}/{stats['total_questions']}")
            print(f"   â€¢ Äiá»ƒm TB: {stats['avg_overall_score']:.2%}")
            print(f"   â€¢ Keyword Coverage: {stats['avg_keyword_coverage']:.2%}")
            print(f"   â€¢ Source Accuracy: {stats['avg_source_accuracy']:.2%}")
            print(f"   â€¢ Thá»i gian TB: {stats['avg_response_time']:.2f}s")
            print(f"   â€¢ CÃ³ nguá»“n: {stats['with_sources_rate']:.2%}")
        
        summary = report["summary"]
        print("\n" + "-" * 50)
        print("TÃ“M Táº®T")
        print("-" * 50)
        print(f"ğŸ¯ Äiá»ƒm tá»•ng thá»ƒ: {summary['overall_score']:.2%}")
        print(f"âœ… NhÃ³m tá»‘t nháº¥t: {summary['best_group']}")
        print(f"âš ï¸  NhÃ³m cáº§n cáº£i thiá»‡n: {summary['worst_group']}")
        print(f"â±ï¸  Thá»i gian TB: {summary['avg_response_time']}s")
        print(f"\nğŸ’¡ Khuyáº¿n nghá»‹: {summary['recommendation']}")
        
        print("\n" + "=" * 70)


# ============================================
# MAIN EXECUTION
# ============================================

if __name__ == "__main__":
    print("ğŸš€ Khá»Ÿi táº¡o há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡...")
    
    # Load pipeline
    from sentence_transformers import SentenceTransformer
    
    print("ğŸ“¦ Loading embedding model...")
    embedding_model = SentenceTransformer("google/embeddinggemma-300m")
    
    print("ğŸ”§ Loading RAG pipeline...")
    pipeline = RAGPipeline(
        model_type="gemma",
        verbose=False,
        preloaded_model=embedding_model
    )
    
    # Cháº¡y Ä‘Ã¡nh giÃ¡
    evaluator = EndToEndEvaluator(pipeline)
    results = evaluator.run_evaluation(save_results=True)
    
    print("\nâœ… ÄÃ¡nh giÃ¡ hoÃ n táº¥t!")